{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed1f4ce",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf573ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764625c",
   "metadata": {},
   "source": [
    "## üìÇ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9c57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully\n",
      "booknow_visits shape: (214046, 3)\n",
      "cinePOS_booking shape: (1641966, 4)\n",
      "sample_submission shape: (38062, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "relation = pd.read_csv(\"data/movie_theater_id_relation.csv\")\n",
    "date_info = pd.read_csv(\"data/date_info.csv\")\n",
    "booknow_theaters = pd.read_csv(\"data/booknow_theaters.csv\")\n",
    "cinePOS_booking = pd.read_csv(\"data/cinePOS_booking.csv\")\n",
    "cinePOS_theaters = pd.read_csv(\"data/cinePOS_theaters.csv\")\n",
    "booknow_visits = pd.read_csv(\"data/booknow_visits.csv\")\n",
    "booknow_booking = pd.read_csv(\"data/booknow_booking.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "print(\"‚úÖ Data Loaded Successfully\")\n",
    "print(f\"booknow_visits shape: {booknow_visits.shape}\")\n",
    "print(f\"cinePOS_booking shape: {cinePOS_booking.shape}\")\n",
    "print(f\"sample_submission shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cffb36",
   "metadata": {},
   "source": [
    "## üîó Data Merging & Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77148fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with booknow_visits: (214046, 3)\n",
      "Date range: 2023-01-01 00:00:00 to 2024-02-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Start with booknow_visits as our base dataset\n",
    "df = booknow_visits.copy()\n",
    "df['show_date'] = pd.to_datetime(df['show_date'])\n",
    "\n",
    "print(f\"Starting with booknow_visits: {df.shape}\")\n",
    "print(f\"Date range: {df['show_date'].min()} to {df['show_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166fb7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with booknow_theaters: (214046, 7)\n"
     ]
    }
   ],
   "source": [
    "# Merge with booknow_theaters\n",
    "df = df.merge(booknow_theaters, on='book_theater_id', how='left')\n",
    "print(f\"After merging with booknow_theaters: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff95f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with relation: (214046, 8)\n"
     ]
    }
   ],
   "source": [
    "# Merge with relation (connects book_theater_id to cine_theater_id)\n",
    "df = df.merge(relation, on='book_theater_id', how='left')\n",
    "print(f\"After merging with relation: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920553b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with cinePOS_theaters: (214046, 12)\n"
     ]
    }
   ],
   "source": [
    "# Merge with cinePOS_theaters\n",
    "df = df.merge(cinePOS_theaters, on='cine_theater_id', how='left')\n",
    "print(f\"After merging with cinePOS_theaters: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82961dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with date_info: (214046, 13)\n"
     ]
    }
   ],
   "source": [
    "# Merge with date_info\n",
    "date_info_prep = date_info.copy()\n",
    "date_info_prep['show_date'] = pd.to_datetime(date_info_prep['show_date'])\n",
    "df = df.merge(date_info_prep, on='show_date', how='left')\n",
    "print(f\"After merging with date_info: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "132c2885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with booknow_booking: (214046, 16)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate booknow_booking data\n",
    "booknow_booking_prep = booknow_booking.copy()\n",
    "booknow_booking_prep['show_datetime'] = pd.to_datetime(booknow_booking_prep['show_datetime'])\n",
    "booknow_booking_prep['show_date'] = booknow_booking_prep['show_datetime'].dt.date\n",
    "booknow_booking_prep['show_date'] = pd.to_datetime(booknow_booking_prep['show_date'])\n",
    "\n",
    "booknow_booking_agg = booknow_booking_prep.groupby(['book_theater_id', 'show_date']).agg({\n",
    "    'tickets_booked': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "booknow_booking_agg.columns = ['book_theater_id', 'show_date', 'total_tickets_booknow', 'avg_tickets_booknow', 'num_bookings_booknow']\n",
    "\n",
    "df = df.merge(booknow_booking_agg, on=['book_theater_id', 'show_date'], how='left')\n",
    "print(f\"After merging with booknow_booking: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b66eb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging with cinePOS_booking: (214046, 19)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate cinePOS_booking data\n",
    "cinePOS_booking_prep = cinePOS_booking.copy()\n",
    "cinePOS_booking_prep['show_datetime'] = pd.to_datetime(cinePOS_booking_prep['show_datetime'])\n",
    "cinePOS_booking_prep['show_date'] = cinePOS_booking_prep['show_datetime'].dt.date\n",
    "cinePOS_booking_prep['show_date'] = pd.to_datetime(cinePOS_booking_prep['show_date'])\n",
    "\n",
    "cinePOS_booking_agg = cinePOS_booking_prep.groupby(['cine_theater_id', 'show_date']).agg({\n",
    "    'tickets_sold': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "cinePOS_booking_agg.columns = ['cine_theater_id', 'show_date', 'total_tickets_cinepos', 'avg_tickets_cinepos', 'num_sales_cinepos']\n",
    "\n",
    "df = df.merge(cinePOS_booking_agg, on=['cine_theater_id', 'show_date'], how='left')\n",
    "print(f\"After merging with cinePOS_booking: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0315a9",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cb60a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding temporal features: (214046, 28)\n"
     ]
    }
   ],
   "source": [
    "# Sort by theater and date\n",
    "df = df.sort_values(['book_theater_id', 'show_date']).reset_index(drop=True)\n",
    "\n",
    "# Extract temporal features\n",
    "df['year'] = df['show_date'].dt.year\n",
    "df['month'] = df['show_date'].dt.month\n",
    "df['day'] = df['show_date'].dt.day\n",
    "df['day_of_year'] = df['show_date'].dt.dayofyear\n",
    "df['week_of_year'] = df['show_date'].dt.isocalendar().week\n",
    "df['quarter'] = df['show_date'].dt.quarter\n",
    "df['is_weekend'] = df['show_date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "df['is_month_start'] = df['show_date'].dt.is_month_start.astype(int)\n",
    "df['is_month_end'] = df['show_date'].dt.is_month_end.astype(int)\n",
    "\n",
    "print(f\"After adding temporal features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6055e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding lag features: (214046, 34)\n"
     ]
    }
   ],
   "source": [
    "# Create lag features\n",
    "lag_days = [1, 2, 3, 7, 14, 28]\n",
    "\n",
    "for lag in lag_days:\n",
    "    df[f'audience_lag_{lag}'] = df.groupby('book_theater_id')['audience_count'].shift(lag)\n",
    "\n",
    "print(f\"After adding lag features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b17794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding rolling features: (214046, 43)\n"
     ]
    }
   ],
   "source": [
    "# Create rolling window statistics\n",
    "rolling_windows = [7, 14, 28]\n",
    "\n",
    "for window in rolling_windows:\n",
    "    df[f'audience_rolling_mean_{window}'] = (\n",
    "        df.groupby('book_theater_id')['audience_count']\n",
    "        .transform(lambda x: x.shift(1).rolling(window, min_periods=1).mean())\n",
    "    )\n",
    "    df[f'audience_rolling_std_{window}'] = (\n",
    "        df.groupby('book_theater_id')['audience_count']\n",
    "        .transform(lambda x: x.shift(1).rolling(window, min_periods=1).std())\n",
    "    )\n",
    "    df[f'audience_rolling_max_{window}'] = (\n",
    "        df.groupby('book_theater_id')['audience_count']\n",
    "        .transform(lambda x: x.shift(1).rolling(window, min_periods=1).max())\n",
    "    )\n",
    "\n",
    "print(f\"After adding rolling features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0545b532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding theater statistics: (214046, 48)\n"
     ]
    }
   ],
   "source": [
    "# Create theater statistics\n",
    "theater_stats = df.groupby('book_theater_id')['audience_count'].agg([\n",
    "    'mean', 'median', 'std', 'min', 'max'\n",
    "]).reset_index()\n",
    "theater_stats.columns = ['book_theater_id', 'theater_avg_audience', 'theater_median_audience', \n",
    "                         'theater_std_audience', 'theater_min_audience', 'theater_max_audience']\n",
    "\n",
    "df = df.merge(theater_stats, on='book_theater_id', how='left')\n",
    "print(f\"After adding theater statistics: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71324680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding categorical features: (214046, 51)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_dow = LabelEncoder()\n",
    "df['day_of_week_encoded'] = le_dow.fit_transform(df['day_of_week'].fillna('Unknown'))\n",
    "\n",
    "df['theater_type_x'] = df['theater_type_x'].fillna('Unknown')\n",
    "df['theater_type_y'] = df['theater_type_y'].fillna('Unknown')\n",
    "\n",
    "le_type_x = LabelEncoder()\n",
    "le_type_y = LabelEncoder()\n",
    "df['theater_type_x_encoded'] = le_type_x.fit_transform(df['theater_type_x'])\n",
    "df['theater_type_y_encoded'] = le_type_y.fit_transform(df['theater_type_y'])\n",
    "\n",
    "print(f\"After encoding categorical features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e0766",
   "metadata": {},
   "source": [
    "## üìä Data Preparation for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2b0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 44\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns\n",
    "exclude_cols = ['book_theater_id', 'show_date', 'audience_count', 'cine_theater_id', \n",
    "                'day_of_week', 'theater_type_x', 'theater_type_y']\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf3e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (204074, 51)\n",
      "  Date range: 2023-01-01 00:00:00 to 2024-02-14 00:00:00\n",
      "Validation set: (9972, 51)\n",
      "  Date range: 2024-02-15 00:00:00 to 2024-02-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Time-based train-validation split\n",
    "train_end_date = pd.Timestamp('2024-02-14')\n",
    "val_start_date = pd.Timestamp('2024-02-15')\n",
    "\n",
    "train_df = df[df['show_date'] <= train_end_date].copy()\n",
    "val_df = df[df['show_date'] >= val_start_date].copy()\n",
    "\n",
    "print(f\"Training set: {train_df.shape}\")\n",
    "print(f\"  Date range: {train_df['show_date'].min()} to {train_df['show_date'].max()}\")\n",
    "print(f\"Validation set: {val_df.shape}\")\n",
    "print(f\"  Date range: {val_df['show_date'].min()} to {val_df['show_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15575617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (204074, 44)\n",
      "X_val shape: (9972, 44)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "for col in feature_cols:\n",
    "    if train_df[col].dtype in ['float64', 'int64']:\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col] = train_df[col].fillna(median_val)\n",
    "        val_df[col] = val_df[col].fillna(median_val)\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['audience_count']\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df['audience_count']\n",
    "\n",
    "# Fill any remaining NaN\n",
    "X_train = X_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "# Convert object columns to numeric\n",
    "for col in X_train.select_dtypes(include='object').columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0)\n",
    "    X_val[col] = pd.to_numeric(X_val[col], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c956f1",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "992d5138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ML libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import ML libraries\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print(\"‚úÖ ML libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "400e41b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM Model...\n",
      "\n",
      "============================================================\n",
      "LightGBM Results:\n",
      "============================================================\n",
      "Train MAE: 13.5349\n",
      "Val MAE:   13.5418\n",
      "Train RMSE: 19.6052\n",
      "Val RMSE:   19.5897\n",
      "Val R¬≤:     0.6158\n",
      "\n",
      "============================================================\n",
      "LightGBM Results:\n",
      "============================================================\n",
      "Train MAE: 13.5349\n",
      "Val MAE:   13.5418\n",
      "Train RMSE: 19.6052\n",
      "Val RMSE:   19.5897\n",
      "Val R¬≤:     0.6158\n"
     ]
    }
   ],
   "source": [
    "# Train LightGBM Model\n",
    "print(\"Training LightGBM Model...\")\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_lgb = np.clip(lgb_model.predict(X_train), 0, None)\n",
    "y_pred_val_lgb = np.clip(lgb_model.predict(X_val), 0, None)\n",
    "\n",
    "train_mae_lgb = mean_absolute_error(y_train, y_pred_train_lgb)\n",
    "val_mae_lgb = mean_absolute_error(y_val, y_pred_val_lgb)\n",
    "train_rmse_lgb = np.sqrt(mean_squared_error(y_train, y_pred_train_lgb))\n",
    "val_rmse_lgb = np.sqrt(mean_squared_error(y_val, y_pred_val_lgb))\n",
    "val_r2_lgb = r2_score(y_val, y_pred_val_lgb)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"LightGBM Results:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Train MAE: {train_mae_lgb:.4f}\")\n",
    "print(f\"Val MAE:   {val_mae_lgb:.4f}\")\n",
    "print(f\"Train RMSE: {train_rmse_lgb:.4f}\")\n",
    "print(f\"Val RMSE:   {val_rmse_lgb:.4f}\")\n",
    "print(f\"Val R¬≤:     {val_r2_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd1a65a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model...\n",
      "\n",
      "============================================================\n",
      "XGBoost Results:\n",
      "============================================================\n",
      "Train MAE: 11.0082\n",
      "Val MAE:   13.3933\n",
      "Train RMSE: 15.1448\n",
      "Val RMSE:   19.4217\n",
      "Val R¬≤:     0.6223\n",
      "\n",
      "============================================================\n",
      "XGBoost Results:\n",
      "============================================================\n",
      "Train MAE: 11.0082\n",
      "Val MAE:   13.3933\n",
      "Train RMSE: 15.1448\n",
      "Val RMSE:   19.4217\n",
      "Val R¬≤:     0.6223\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost Model\n",
    "print(\"Training XGBoost Model...\")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_xgb = np.clip(xgb_model.predict(X_train), 0, None)\n",
    "y_pred_val_xgb = np.clip(xgb_model.predict(X_val), 0, None)\n",
    "\n",
    "train_mae_xgb = mean_absolute_error(y_train, y_pred_train_xgb)\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_pred_val_xgb)\n",
    "train_rmse_xgb = np.sqrt(mean_squared_error(y_train, y_pred_train_xgb))\n",
    "val_rmse_xgb = np.sqrt(mean_squared_error(y_val, y_pred_val_xgb))\n",
    "val_r2_xgb = r2_score(y_val, y_pred_val_xgb)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"XGBoost Results:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Train MAE: {train_mae_xgb:.4f}\")\n",
    "print(f\"Val MAE:   {val_mae_xgb:.4f}\")\n",
    "print(f\"Train RMSE: {train_rmse_xgb:.4f}\")\n",
    "print(f\"Val RMSE:   {val_rmse_xgb:.4f}\")\n",
    "print(f\"Val R¬≤:     {val_r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5619eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Most Important Features:\n",
      "============================================================\n",
      "                 feature  importance\n",
      "          audience_lag_1        1891\n",
      "    theater_std_audience        1695\n",
      "             day_of_year        1672\n",
      "    theater_max_audience        1579\n",
      "          audience_lag_7        1484\n",
      "     day_of_week_encoded        1425\n",
      "          audience_lag_2        1389\n",
      "          audience_lag_3        1242\n",
      "         audience_lag_14        1206\n",
      "    theater_avg_audience        1071\n",
      " audience_rolling_mean_7        1070\n",
      "                     day        1065\n",
      "         audience_lag_28        1061\n",
      " theater_median_audience        1000\n",
      "audience_rolling_mean_28         990\n",
      "audience_rolling_mean_14         921\n",
      "  audience_rolling_max_7         910\n",
      "  audience_rolling_std_7         805\n",
      " audience_rolling_max_28         773\n",
      " audience_rolling_std_28         741\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(\"=\"*60)\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63d498",
   "metadata": {},
   "source": [
    "## üéØ Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf37027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (38062, 3)\n",
      "Date range: 2024-03-01 00:00:00 to 2024-04-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data\n",
    "test_data = sample_submission[['ID']].copy()\n",
    "test_data['book_theater_id'] = test_data['ID'].str.rsplit('_', n=1).str[0]\n",
    "test_data['show_date'] = test_data['ID'].str.rsplit('_', n=1).str[1]\n",
    "test_data['show_date'] = pd.to_datetime(test_data['show_date'])\n",
    "\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Date range: {test_data['show_date'].min()} to {test_data['show_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f02808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature generation function created\n"
     ]
    }
   ],
   "source": [
    "# Function to create features for test data\n",
    "def create_features_for_prediction(test_df, historical_df, feature_cols_list):\n",
    "    \"\"\"\n",
    "    Create features for test data using historical data for lag/rolling features\n",
    "    \"\"\"\n",
    "    hist_minimal = historical_df[['book_theater_id', 'show_date', 'audience_count']].copy()\n",
    "    \n",
    "    test_df = test_df.copy()\n",
    "    test_df['audience_count'] = np.nan\n",
    "    combined = pd.concat([hist_minimal, test_df[['book_theater_id', 'show_date', 'audience_count']]], ignore_index=True)\n",
    "    combined = combined.sort_values(['book_theater_id', 'show_date']).reset_index(drop=True)\n",
    "    \n",
    "    # Merge with all data sources\n",
    "    combined = combined.merge(booknow_theaters, on='book_theater_id', how='left', suffixes=('', '_bn'))\n",
    "    combined = combined.merge(relation, on='book_theater_id', how='left')\n",
    "    combined = combined.merge(cinePOS_theaters, on='cine_theater_id', how='left', suffixes=('_x', '_y'))\n",
    "    \n",
    "    date_info_prep = date_info.copy()\n",
    "    date_info_prep['show_date'] = pd.to_datetime(date_info_prep['show_date'])\n",
    "    combined = combined.merge(date_info_prep, on='show_date', how='left')\n",
    "    \n",
    "    combined = combined.merge(booknow_booking_agg, on=['book_theater_id', 'show_date'], how='left')\n",
    "    combined = combined.merge(cinePOS_booking_agg, on=['cine_theater_id', 'show_date'], how='left')\n",
    "    \n",
    "    # Add temporal features\n",
    "    combined['year'] = combined['show_date'].dt.year\n",
    "    combined['month'] = combined['show_date'].dt.month\n",
    "    combined['day'] = combined['show_date'].dt.day\n",
    "    combined['day_of_year'] = combined['show_date'].dt.dayofyear\n",
    "    combined['week_of_year'] = combined['show_date'].dt.isocalendar().week\n",
    "    combined['quarter'] = combined['show_date'].dt.quarter\n",
    "    combined['is_weekend'] = combined['show_date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "    combined['is_month_start'] = combined['show_date'].dt.is_month_start.astype(int)\n",
    "    combined['is_month_end'] = combined['show_date'].dt.is_month_end.astype(int)\n",
    "    \n",
    "    # Add lag features\n",
    "    for lag in [1, 2, 3, 7, 14, 28]:\n",
    "        combined[f'audience_lag_{lag}'] = combined.groupby('book_theater_id')['audience_count'].shift(lag)\n",
    "    \n",
    "    # Add rolling features\n",
    "    for window in [7, 14, 28]:\n",
    "        combined[f'audience_rolling_mean_{window}'] = (\n",
    "            combined.groupby('book_theater_id')['audience_count']\n",
    "            .transform(lambda x: x.shift(1).rolling(window, min_periods=1).mean())\n",
    "        )\n",
    "        combined[f'audience_rolling_std_{window}'] = (\n",
    "            combined.groupby('book_theater_id')['audience_count']\n",
    "            .transform(lambda x: x.shift(1).rolling(window, min_periods=1).std())\n",
    "        )\n",
    "        combined[f'audience_rolling_max_{window}'] = (\n",
    "            combined.groupby('book_theater_id')['audience_count']\n",
    "            .transform(lambda x: x.shift(1).rolling(window, min_periods=1).max())\n",
    "        )\n",
    "    \n",
    "    # Add theater statistics\n",
    "    combined = combined.merge(theater_stats, on='book_theater_id', how='left')\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    combined['day_of_week_encoded'] = le_dow.transform(combined['day_of_week'].fillna('Unknown'))\n",
    "    combined['theater_type_x'] = combined['theater_type_x'].fillna('Unknown')\n",
    "    combined['theater_type_y'] = combined['theater_type_y'].fillna('Unknown')\n",
    "    combined['theater_type_x_encoded'] = le_type_x.transform(combined['theater_type_x'])\n",
    "    combined['theater_type_y_encoded'] = le_type_y.transform(combined['theater_type_y'])\n",
    "    \n",
    "    # Extract test rows\n",
    "    test_features = combined[combined['audience_count'].isna()].copy()\n",
    "    available_cols = [col for col in feature_cols_list if col in test_features.columns]\n",
    "    \n",
    "    return test_features[available_cols]\n",
    "\n",
    "print(\"‚úÖ Feature generation function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9cb07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features for test set...\n",
      "Test features shape: (38062, 44)\n",
      "Missing values: 0\n",
      "Test features shape: (38062, 44)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Generate features for test set\n",
    "print(\"Generating features for test set...\")\n",
    "X_test = create_features_for_prediction(test_data, df, feature_cols)\n",
    "\n",
    "# Fill missing values\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype in ['float64', 'int64']:\n",
    "        X_test[col] = X_test[col].fillna(X_train[col].median())\n",
    "\n",
    "# Convert object columns\n",
    "for col in X_test.select_dtypes(include='object').columns:\n",
    "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0)\n",
    "\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Missing values: {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03087319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions with both models...\n",
      "\n",
      "Predictions statistics:\n",
      "  XGBoost - Min: 2.23, Max: 173.47, Mean: 41.35\n",
      "  LightGBM - Min: 3.33, Max: 142.37, Mean: 39.04\n",
      "  Ensemble - Min: 2.78, Max: 152.11, Mean: 40.20\n",
      "\n",
      "Predictions statistics:\n",
      "  XGBoost - Min: 2.23, Max: 173.47, Mean: 41.35\n",
      "  LightGBM - Min: 3.33, Max: 142.37, Mean: 39.04\n",
      "  Ensemble - Min: 2.78, Max: 152.11, Mean: 40.20\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions with both models...\")\n",
    "\n",
    "test_predictions_xgb = np.clip(xgb_model.predict(X_test), 0, None)\n",
    "test_predictions_lgb = np.clip(lgb_model.predict(X_test), 0, None)\n",
    "\n",
    "# Ensemble: average of both models\n",
    "test_predictions_ensemble = (test_predictions_xgb + test_predictions_lgb) / 2\n",
    "\n",
    "print(f\"\\nPredictions statistics:\")\n",
    "print(f\"  XGBoost - Min: {test_predictions_xgb.min():.2f}, Max: {test_predictions_xgb.max():.2f}, Mean: {test_predictions_xgb.mean():.2f}\")\n",
    "print(f\"  LightGBM - Min: {test_predictions_lgb.min():.2f}, Max: {test_predictions_lgb.max():.2f}, Mean: {test_predictions_lgb.mean():.2f}\")\n",
    "print(f\"  Ensemble - Min: {test_predictions_ensemble.min():.2f}, Max: {test_predictions_ensemble.max():.2f}, Mean: {test_predictions_ensemble.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1daa069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ SUBMISSION FILE CREATED!\n",
      "============================================================\n",
      "Filename: submission.csv\n",
      "Shape: (38062, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "                      ID  audience_count\n",
      "0  book_00001_2024-03-01              33\n",
      "1  book_00001_2024-03-02              51\n",
      "2  book_00001_2024-03-03              55\n",
      "3  book_00001_2024-03-04              50\n",
      "4  book_00001_2024-03-06              34\n",
      "5  book_00001_2024-03-07              33\n",
      "6  book_00001_2024-03-08              31\n",
      "7  book_00001_2024-03-09              50\n",
      "8  book_00001_2024-03-10              60\n",
      "9  book_00001_2024-03-11              45\n",
      "\n",
      "Last 10 predictions:\n",
      "                          ID  audience_count\n",
      "38052  book_00829_2024-04-11              15\n",
      "38053  book_00829_2024-04-12              14\n",
      "38054  book_00829_2024-04-13              15\n",
      "38055  book_00829_2024-04-14              18\n",
      "38056  book_00829_2024-04-15              16\n",
      "38057  book_00829_2024-04-18              14\n",
      "38058  book_00829_2024-04-19              14\n",
      "38059  book_00829_2024-04-20              15\n",
      "38060  book_00829_2024-04-21              19\n",
      "38061  book_00829_2024-04-22              16\n",
      "\n",
      "Predictions distribution:\n",
      "count    38062.000000\n",
      "mean        39.697362\n",
      "std         17.230940\n",
      "min          2.000000\n",
      "25%         26.000000\n",
      "50%         37.000000\n",
      "75%         51.000000\n",
      "max        152.000000\n",
      "Name: audience_count, dtype: float64\n",
      "\n",
      "‚úÖ SUBMISSION FILE CREATED!\n",
      "============================================================\n",
      "Filename: submission.csv\n",
      "Shape: (38062, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "                      ID  audience_count\n",
      "0  book_00001_2024-03-01              33\n",
      "1  book_00001_2024-03-02              51\n",
      "2  book_00001_2024-03-03              55\n",
      "3  book_00001_2024-03-04              50\n",
      "4  book_00001_2024-03-06              34\n",
      "5  book_00001_2024-03-07              33\n",
      "6  book_00001_2024-03-08              31\n",
      "7  book_00001_2024-03-09              50\n",
      "8  book_00001_2024-03-10              60\n",
      "9  book_00001_2024-03-11              45\n",
      "\n",
      "Last 10 predictions:\n",
      "                          ID  audience_count\n",
      "38052  book_00829_2024-04-11              15\n",
      "38053  book_00829_2024-04-12              14\n",
      "38054  book_00829_2024-04-13              15\n",
      "38055  book_00829_2024-04-14              18\n",
      "38056  book_00829_2024-04-15              16\n",
      "38057  book_00829_2024-04-18              14\n",
      "38058  book_00829_2024-04-19              14\n",
      "38059  book_00829_2024-04-20              15\n",
      "38060  book_00829_2024-04-21              19\n",
      "38061  book_00829_2024-04-22              16\n",
      "\n",
      "Predictions distribution:\n",
      "count    38062.000000\n",
      "mean        39.697362\n",
      "std         17.230940\n",
      "min          2.000000\n",
      "25%         26.000000\n",
      "50%         37.000000\n",
      "75%         51.000000\n",
      "max        152.000000\n",
      "Name: audience_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission = sample_submission[['ID']].copy()\n",
    "submission['audience_count'] = test_predictions_ensemble.astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ SUBMISSION FILE CREATED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Filename: submission.csv\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nLast 10 predictions:\")\n",
    "print(submission.tail(10))\n",
    "print(f\"\\nPredictions distribution:\")\n",
    "print(submission['audience_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575fa8e",
   "metadata": {},
   "source": [
    "## üìù Summary\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Data Loading**: Loaded 7 datasets (214,046 training records)\n",
    "2. **Data Merging**: Integrated all data sources based on booknow_visits\n",
    "3. **Feature Engineering**: Created 44 features including lag, rolling, and temporal features\n",
    "4. **Model Training**: Trained LightGBM and XGBoost (Validation MAE: ~13.4)\n",
    "5. **Predictions**: Generated 38,062 predictions using ensemble approach\n",
    "6. **Output**: Saved to `submission.csv`\n",
    "\n",
    "‚úÖ **Ready for submission!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
